{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLu(x):\n",
    "    # if (x < 0):\n",
    "    #     return 0\n",
    "    # return x\n",
    "    return np.maximum(0,x)\n",
    "\n",
    "def softmax(x):\n",
    "    sum = 0\n",
    "    for i in range(len(x)):\n",
    "        sum += np.exp(x[i])\n",
    "    return np.exp(x) / sum\n",
    "\n",
    "\n",
    "# def Max3x3(M): // a adapter car pour le moment j'utilise  np.max ca fait le taff\n",
    "#     max = M[0][0]\n",
    "#     for i in range(3):\n",
    "#         for j in range(3):\n",
    "#             if M[i][j] > max:\n",
    "#                 max = M[i][j]\n",
    "#     return max\n",
    "\n",
    "def MaxPool(M):\n",
    "    y,x,num_channels = M.shape\n",
    "    i = 0\n",
    "    j = 0\n",
    "    output_height = (y - 3) // 2 + 1\n",
    "    output_width = (x - 3) // 2 + 1\n",
    "    print(f\"output height: {output_height}, output width: {output_width}\")\n",
    "    output = np.zeros((output_height, output_width, num_channels))\n",
    "\n",
    "    for c in range(num_channels):\n",
    "        for i in range(0, output_height):\n",
    "            for j in range(0, output_width):\n",
    "                start_i, start_j = i * 2, j * 2\n",
    "                region = M[start_i:start_i + 3, start_j:start_j + 3, c] #j'ai enlever output x et y car pas besoin et re for pour eviter de remettre à 0\n",
    "                output[i, j, c] = np.max(region)\n",
    "    return output\n",
    "\n",
    "def MaxPool_v2(M):\n",
    "    y,x,num_channels = M.shape\n",
    "    i = 0\n",
    "    j = 0\n",
    "    output_height = y // 2\n",
    "    output_width = x // 2\n",
    "    output = np.zeros((output_height, output_width, num_channels))\n",
    "    for c in range(num_channels):\n",
    "        for i in range(0, output_height):\n",
    "            for j in range(0, output_width):\n",
    "                start_i, start_j = i * 2, j * 2\n",
    "                if (start_i + 3 > y):\n",
    "                    if(start_j + 3 > x):\n",
    "                        region = M[start_i:y, start_j:start_j + 3, c]\n",
    "                    else:\n",
    "                        region = M[start_i:y, start_j:x, c]\n",
    "                elif (start_j + 3 > x):\n",
    "                    region = M[start_i:start_i + 3, start_j:x, c]\n",
    "                else:\n",
    "                    region = M[start_i:start_i + 3, start_j:start_j + 3, c] #j'ai enlever output x et y car pas besoin et re for pour eviter de remettre à 0\n",
    "                output[i, j, c] = np.max(region)\n",
    "    return output\n",
    "\n",
    "def convolution(image, Ks, biais):\n",
    "    image_height, image_width, image_channels = image.shape\n",
    "    K_height, K_width, _, num_filters,= Ks.shape\n",
    "    output_height = image_height\n",
    "    output_width = image_width\n",
    "    output = np.zeros((output_height, output_width, num_filters))\n",
    "    padded_image = np.pad(image, ((2, 2), (2, 2), (0, 0)), mode='constant') #j'ai vu qu'il fallait faire du padding pour conserver les dimensions de notre frame 3D \n",
    "   \n",
    "    for f in range(num_filters):\n",
    "        conv_sum = np.zeros((output_height, output_width))\n",
    "        for c in range(image_channels):  \n",
    "            for i in range(output_height):\n",
    "                for j in range(output_width):\n",
    "                    region = padded_image[i:i+K_height, j:j+K_width, c]\n",
    "                    conv_sum[i, j] += np.sum(region * Ks[:, :, c, f])\n",
    "        output[:, :, f] = ReLu(conv_sum + biais[f])\n",
    "   \n",
    "    return output\n",
    "\n",
    "def c_reshape(M):\n",
    "    height, width, channels = M.shape\n",
    "    output = M\n",
    "    return output.reshape(height*width*channels) # On garde comme ça pour l'instant mais à changer pour le matériel\n",
    "\n",
    "def FCP(M, weights, bias): # Fully Connected Perceptron\n",
    "    '''\n",
    "    M : (180,)\n",
    "    weights : (180, 10)\n",
    "    bias : (10,)\n",
    "    output : (10,)\n",
    "    '''\n",
    "    M = M.T\n",
    "    output = softmax(M.dot(weights) + bias)\n",
    "    return output\n",
    "\n",
    "def normalize(M):\n",
    "    min_val = np.min(M)\n",
    "    max_val = np.max(M)\n",
    "    \n",
    "    M_normalized = (M - min_val) / (max_val - min_val)\n",
    "    \n",
    "    return M_normalized\n",
    "\n",
    "def normalize_image(I):\n",
    "    N = I.size\n",
    "    mu = np.mean(I)\n",
    "    sigma = np.std(I)\n",
    "\n",
    "    normalized = (I - mu) / max(sigma, 1 / np.sqrt(N))\n",
    "\n",
    "    return normalized\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 24, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def load_cifar10_batch(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        # Each image is 3073 bytes (1 label + 3072 pixel values)\n",
    "        data = np.frombuffer(file.read(), dtype=np.uint8)\n",
    "        \n",
    "    # Reshape to 10000 rows of 3073 bytes\n",
    "    data = data.reshape(-1, 3073)\n",
    "    \n",
    "    # First column is labels, rest are pixel values\n",
    "    labels = data[:, 0]\n",
    "    images = data[:, 1:]\n",
    "    \n",
    "    # Reshape image data: 3072 pixels -> 3 channels (32x32)\n",
    "    images = images.reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)  # Shape (10000, 32, 32, 3)\n",
    "    \n",
    "    resized_images = np.array([image[4:28, 4:28] for image in images])\n",
    "    \n",
    "    return resized_images, labels\n",
    "\n",
    "def load_class_names(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        class_names = [line.strip() for line in file]\n",
    "    return class_names\n",
    "\n",
    "\n",
    "def plot_sample_image(images, labels, class_names, index=0):\n",
    "    # Select image and label at the given index\n",
    "    image = images[index]\n",
    "    label = labels[index]\n",
    "    class_name = class_names[label]\n",
    "\n",
    "    print(image.shape)\n",
    "    \n",
    "    # Plot the image\n",
    "    plt.imshow(image)\n",
    "    plt.title(f\"Label: {label} ({class_name})\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Usage:\n",
    "images, labels = load_cifar10_batch('../../Downloads/cifar10_data/cifar-10-batches-bin/data_batch_1.bin')\n",
    "class_names = load_class_names('../../Downloads/cifar10_data/cifar-10-batches-bin/batches.meta.txt')\n",
    "\n",
    "plot_sample_image(images, labels, class_names, index=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST SUR IMAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tensor_data(tensor_name, raw_data):\n",
    "    cleaned_string = raw_data.replace('[', '').replace(']', '').replace('\\n', ' ')\n",
    "    float_list = [float(x) for x in cleaned_string.split()]\n",
    "    tensor_dict[tensor_name] = np.array(float_list)\n",
    "\n",
    "tensor_dict = {}\n",
    "\n",
    "with open('../../Downloads/CNN_coeff_3x3.txt', 'r') as file:\n",
    "    tensor_name = None\n",
    "    raw_data = ''\n",
    "    \n",
    "    for line in file:\n",
    "        if line.startswith('tensor_name:'):\n",
    "            if tensor_name:\n",
    "                process_tensor_data(tensor_name, raw_data)\n",
    "            tensor_name = line.split(':')[1].strip()\n",
    "            raw_data = ''\n",
    "        else:\n",
    "            raw_data += line.strip() + '\\n'\n",
    "    \n",
    "    if tensor_name:\n",
    "        process_tensor_data(tensor_name, raw_data)\n",
    "\n",
    "def reshape_array_parameters():\n",
    "    for tensor_name, parameter_array in tensor_dict.items():\n",
    "        if tensor_name == 'conv1/biases':\n",
    "            tensor_dict[tensor_name] = parameter_array.reshape(64,)\n",
    "        elif tensor_name == 'conv1/weights':\n",
    "            tensor_dict[tensor_name] = parameter_array.reshape(3, 3, 3, 64)\n",
    "        elif tensor_name == 'conv2/biases':\n",
    "            tensor_dict[tensor_name] = parameter_array.reshape(32,)\n",
    "        elif tensor_name == 'conv2/weights':\n",
    "            tensor_dict[tensor_name] = parameter_array.reshape(3, 3, 64, 32)\n",
    "        elif tensor_name == 'conv3/biases':\n",
    "            tensor_dict[tensor_name] = parameter_array.reshape(20,)\n",
    "        elif tensor_name == 'conv3/weights':\n",
    "            tensor_dict[tensor_name] = parameter_array.reshape(3, 3, 32, 20)\n",
    "        elif tensor_name == 'local3/biases':\n",
    "            tensor_dict[tensor_name] = parameter_array.reshape(10,)\n",
    "        elif tensor_name == 'local3/weights':\n",
    "            tensor_dict[tensor_name] = parameter_array.reshape(180, 10)\n",
    "\n",
    "reshape_array_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.33150375, -0.05496363,  1.30825186,  2.52893686,  1.00788128,\n",
       "        2.28100443,  1.75292468,  1.02082717,  0.45848575,  0.17053629])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_dict['local3/biases']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.83625288e-04 9.72199457e-01 2.40845732e-05 2.05424540e-04\n",
      " 4.46224817e-04 1.92343374e-04 6.26408278e-05 3.66050027e-03\n",
      " 1.45930786e-04 2.27797682e-02]\n",
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'automobile'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_image = images[5]\n",
    "input_image = normalize_image(input_image)\n",
    "k1 = tensor_dict['conv1/weights']\n",
    "biais1 = tensor_dict['conv1/biases']\n",
    "k2 = tensor_dict['conv2/weights']\n",
    "biais2 = tensor_dict['conv2/biases']\n",
    "k3 = tensor_dict['conv3/weights']\n",
    "biais3 = tensor_dict['conv3/biases']\n",
    "weights_fcp = tensor_dict['local3/weights']\n",
    "biais_fcp = tensor_dict['local3/biases']\n",
    "\n",
    "conv1 = convolution(input_image, k1, biais1)\n",
    "maxpool1 = MaxPool_v2(conv1)\n",
    "conv2 = convolution(maxpool1, k2, biais2)\n",
    "maxpool2 = MaxPool_v2(conv2)\n",
    "conv3 = convolution(maxpool2, k3, biais3)\n",
    "maxpool3 = MaxPool_v2(conv3)\n",
    "reshape = c_reshape(maxpool3)\n",
    "output = FCP(reshape, weights_fcp, biais_fcp)\n",
    "print(output)\n",
    "np.sum(output)\n",
    "index_max = np.argmax(output)\n",
    "print(index_max)\n",
    "class_names[index_max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'frog'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names[6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modèle Complet de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.16191732e-02 7.45023220e-03 2.34179300e-04 1.33853087e-01\n",
      " 1.15099113e-04 5.57206988e-01 6.08066200e-03 1.36721093e-01\n",
      " 3.73450576e-02 6.93744283e-02]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_image = np.random.rand(24, 24, 3)\n",
    "k1 = np.random.rand(3, 3, 3, 64)\n",
    "biais1 = np.random.rand(64)\n",
    "k2 = np.random.rand(3, 3, 64, 32)\n",
    "biais2 = np.random.rand(32)\n",
    "k3 = np.random.rand(3, 3, 32, 20)\n",
    "biais3 = np.random.rand(20)\n",
    "weights_fcp = np.random.rand(180, 10)\n",
    "biais_fcp = np.random.rand(10,)\n",
    "\n",
    "conv1 = convolution(input_image, k1, biais1)\n",
    "maxpool1 = MaxPool_v2(conv1)\n",
    "conv2 = convolution(maxpool1, k2, biais2)\n",
    "maxpool2 = MaxPool_v2(conv2)\n",
    "conv3 = convolution(maxpool2, k3, biais3)\n",
    "maxpool3 = MaxPool_v2(conv3)\n",
    "norm1=normalize(maxpool3)#je l'ai fait de manière un peu vener mais ça marche\n",
    "reshape = c_reshape(norm1)\n",
    "output = FCP(reshape, weights_fcp, biais_fcp)\n",
    "print(output)\n",
    "np.sum(output)\n",
    "# PROBLEME AVEC EXPONENTIELLE... peut etre qu'avec les parametres du profs + en normalisant comme on devra le faire on aura pas ces problemes mais je ne suis pas sur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshape  (180,)\n",
      "output  (10,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2.20170380e-03, 4.67058942e-01, 7.38930578e-03, 1.28046624e-04,\n",
       "       1.95621841e-03, 6.18633527e-05, 4.32034240e-01, 6.14900538e-02,\n",
       "       2.69413156e-02, 7.38310749e-04])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_image = np.random.rand(3, 3, 20)\n",
    "weights = np.random.rand(180, 10)\n",
    "biais1 = np.random.rand(10,)\n",
    "\n",
    "reshape = c_reshape(input_image)\n",
    "output = FCP(reshape, weights, biais1)\n",
    "print(\"Reshape \", reshape.shape)\n",
    "print(\"output \", output.shape)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "matrice = np.random.randint(0, 256, size=(24, 24, 3))\n",
    "\n",
    "R = matrice[:, :, 0]\n",
    "G = matrice[:, :, 1]\n",
    "B = matrice[:, :, 2]\n",
    "\n",
    "# print(\"Canal Rouge (R):\")\n",
    "# print(R)\n",
    "# print(\"\\nCanal Vert (G):\")\n",
    "# print(G)\n",
    "# print(\"\\nCanal Bleu (B):\")\n",
    "# print(B)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output height: 11, output width: 11\n"
     ]
    }
   ],
   "source": [
    "m2=MaxPool(matrice)\n",
    "R2 = m2[:, :, 0]\n",
    "G2 = m2[:, :, 1]\n",
    "B2 = m2[:, :, 2]\n",
    "\n",
    "# print(\"Canal Rouge (R):\")\n",
    "# print(R2)\n",
    "# print(\"\\nCanal Vert (G):\")\n",
    "# print(G2)\n",
    "# print(\"\\nCanal Bleu (B):\")\n",
    "# print(B2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convolution 1  (24, 24, 64)\n",
      "Maxpool 1  (12, 12, 64)\n"
     ]
    }
   ],
   "source": [
    "input_image = np.random.rand(24, 24, 3)\n",
    "k1 = np.random.rand(64, 3, 3, 3)  # 64 filtres de 3x3x3\n",
    "biais1 = np.random.rand(64)\n",
    "\n",
    "conv1_output = convolution(input_image, k1, biais1)\n",
    "maxpool_output = MaxPool_v2(conv1_output)\n",
    "print(\"Convolution 1 \", conv1_output.shape)  # (24, 24, 64)\n",
    "print(\"Maxpool 1 \", maxpool_output.shape)  # (3, 3, 20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "polito",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
